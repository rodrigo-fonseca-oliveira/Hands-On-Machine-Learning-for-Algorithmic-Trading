{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha Factor Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a mumber of alpha factor candidates that we can use as features in ML models on the Quantopian platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "# import talib\n",
    "import re\n",
    "from statsmodels.api import OLS\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from zipline.research import run_pipeline\n",
    "from zipline.pipeline import Pipeline, factors, filters, classifiers, EquityPricing\n",
    "# from zipline.pipeline.data.builtin import USEquityPricing\n",
    "from zipline.pipeline.factors import (Latest, \n",
    "                                         Returns, \n",
    "                                         AverageDollarVolume, \n",
    "                                         SimpleMovingAverage,\n",
    "                                         EWMA,\n",
    "                                         BollingerBands,\n",
    "                                         CustomFactor,\n",
    "                                        #  MarketCap,\n",
    "                                        SimpleBeta)\n",
    "from zipline.pipeline.filters import StaticAssets #QTradableStocksUS, \n",
    "# from zipline.pipeline.data.quandl import fred_usdontd156n as libor\n",
    "from empyrical import max_drawdown, sortino_ratio\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ################\n",
    "# # Fundamentals #\n",
    "# ################\n",
    "\n",
    "# # Morningstar fundamentals (2002 - Ongoing)\n",
    "# # https://www.quantopian.com/help/fundamentals\n",
    "# from quantopian.pipeline.data import Fundamentals\n",
    "from zipline.pipeline import sharadar\n",
    "\n",
    "\n",
    "# #####################\n",
    "# # Analyst Estimates #\n",
    "# #####################\n",
    "\n",
    "# # Earnings Surprises - Zacks (27 May 2006 - Ongoing)\n",
    "# # https://www.quantopian.com/data/zacks/earnings_surprises\n",
    "# from quantopian.pipeline.data.zacks import EarningsSurprises\n",
    "# from quantopian.pipeline.factors.zacks import BusinessDaysSinceEarningsSurprisesAnnouncement\n",
    "\n",
    "# ##########\n",
    "# # Events #\n",
    "# ##########\n",
    "\n",
    "# # Buyback Announcements - EventVestor (01 Jun 2007 - Ongoing)\n",
    "# # https://www.quantopian.com/data/eventvestor/buyback_auth\n",
    "# from quantopian.pipeline.data.eventvestor import BuybackAuthorizations\n",
    "# from quantopian.pipeline.factors.eventvestor import BusinessDaysSinceBuybackAuth\n",
    "\n",
    "# # CEO Changes - EventVestor (01 Jan 2007 - Ongoing)\n",
    "# # https://www.quantopian.com/data/eventvestor/ceo_change\n",
    "# from quantopian.pipeline.data.eventvestor import CEOChangeAnnouncements\n",
    "\n",
    "# # Dividends - EventVestor (01 Jan 2007 - Ongoing)\n",
    "# # https://www.quantopian.com/data/eventvestor/dividends\n",
    "# from quantopian.pipeline.data.eventvestor import (\n",
    "#     DividendsByExDate,\n",
    "#     DividendsByPayDate,\n",
    "#     DividendsByAnnouncementDate,\n",
    "# )\n",
    "# from quantopian.pipeline.factors.eventvestor import (\n",
    "#     BusinessDaysSincePreviousExDate,\n",
    "#     BusinessDaysUntilNextExDate,\n",
    "#     BusinessDaysSinceDividendAnnouncement,\n",
    "# )\n",
    "\n",
    "# # Earnings Calendar - EventVestor (01 Jan 2007 - Ongoing)\n",
    "# # https://www.quantopian.com/data/eventvestor/earnings_calendar\n",
    "# from quantopian.pipeline.data.eventvestor import EarningsCalendar\n",
    "# from quantopian.pipeline.factors.eventvestor import (\n",
    "#     BusinessDaysUntilNextEarnings,\n",
    "#     BusinessDaysSincePreviousEarnings\n",
    "# )\n",
    "\n",
    "# # 13D Filings - EventVestor (01 Jan 2007 - Ongoing)\n",
    "# # https://www.quantopian.com/data/eventvestor/_13d_filings\n",
    "# from quantopian.pipeline.data.eventvestor import _13DFilings\n",
    "# from quantopian.pipeline.factors.eventvestor import BusinessDaysSince13DFilingsDate\n",
    "\n",
    "# #############\n",
    "# # Sentiment #\n",
    "# #############\n",
    "\n",
    "# # News Sentiment - Sentdex Sentiment Analysis (15 Oct 2012 - Ongoing)\n",
    "# # https://www.quantopian.com/data/sentdex/sentiment\n",
    "# from quantopian.pipeline.data.sentdex import sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trading days per period\n",
    "MONTH = 21\n",
    "YEAR = 12 * MONTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START = '2014-01-01'\n",
    "END = '2015-12-31'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from zipline.pipeline import Pipeline, EquityPricing, master\n",
    "from zipline.pipeline.factors import SimpleMovingAverage\n",
    "from zipline.research import run_pipeline\n",
    "\n",
    "from codeload.pipeline_tutorial.tradable_stocks import TradableStocksUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# UNIVERSE = StaticAssets(symbols(['MSFT', 'AAPL']))\n",
    "# UNIVERSE = Q100US()\n",
    "UNIVERSE = TradableStocksUS(True) & sharadar.SP500.in_sp500.latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Q100US():\n",
    "#     universe = tradable_stocks_us_universe\n",
    "#     return filters.make_us_equity_universe(\n",
    "#         target_size=100,\n",
    "#         rankby=factors.AverageDollarVolume(window_length=200),\n",
    "#         mask=tradable_stocks_us_universe,\n",
    "#         groupby=classifiers.fundamentals.Sector(),\n",
    "#         max_group_weight=0.3,\n",
    "#         smoothing_func=lambda f: f.downsample('month_start'),\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_pipeline():\n",
    "    \n",
    "    \n",
    "    in_sp500 = sharadar.SP500.in_sp500.latest\n",
    "    universe = UNIVERSE & in_sp500\n",
    "    \n",
    "    \n",
    "    # 10-day close price average.\n",
    "    mean_10 = SimpleMovingAverage(inputs=EquityPricing.close, window_length=10, mask=universe)\n",
    "\n",
    "    # 30-day close price average.\n",
    "    mean_30 = SimpleMovingAverage(inputs=EquityPricing.close, window_length=30, mask=universe)\n",
    "\n",
    "    # Percent difference factor.\n",
    "    percent_difference = (mean_10 - mean_30) / mean_30\n",
    "        \n",
    "    return Pipeline(\n",
    "        columns={\n",
    "            'percent_difference': percent_difference,\n",
    "            'sector': master.SecuritiesMaster.usstock_Sector.latest\n",
    "        },\n",
    "        screen=universe\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>percent_difference</th>\n",
       "      <th>sector</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>asset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">2015-05-05 00:00:00+00:00</th>\n",
       "      <th>Equity(FIBBG000C2V3D6 [A])</th>\n",
       "      <td>0.000209</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG005P7Q881 [AAL])</th>\n",
       "      <td>0.008126</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG000B9XRY4 [AAPL])</th>\n",
       "      <td>0.016827</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG0025Y4RY4 [ABBV])</th>\n",
       "      <td>0.060194</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG000MDCQC2 [ABC])</th>\n",
       "      <td>0.006168</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG001D8R5D0 [XYL])</th>\n",
       "      <td>0.018219</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG000BH3GZ2 [YUM])</th>\n",
       "      <td>0.059677</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG000BKPL53 [ZBH])</th>\n",
       "      <td>-0.007930</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG000BX9WL1 [ZION])</th>\n",
       "      <td>0.018272</td>\n",
       "      <td>Financials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG0039320N9 [ZTS])</th>\n",
       "      <td>-0.006146</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>464 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         percent_difference  \\\n",
       "date                      asset                                               \n",
       "2015-05-05 00:00:00+00:00 Equity(FIBBG000C2V3D6 [A])               0.000209   \n",
       "                          Equity(FIBBG005P7Q881 [AAL])             0.008126   \n",
       "                          Equity(FIBBG000B9XRY4 [AAPL])            0.016827   \n",
       "                          Equity(FIBBG0025Y4RY4 [ABBV])            0.060194   \n",
       "                          Equity(FIBBG000MDCQC2 [ABC])             0.006168   \n",
       "...                                                                     ...   \n",
       "                          Equity(FIBBG001D8R5D0 [XYL])             0.018219   \n",
       "                          Equity(FIBBG000BH3GZ2 [YUM])             0.059677   \n",
       "                          Equity(FIBBG000BKPL53 [ZBH])            -0.007930   \n",
       "                          Equity(FIBBG000BX9WL1 [ZION])            0.018272   \n",
       "                          Equity(FIBBG0039320N9 [ZTS])            -0.006146   \n",
       "\n",
       "                                                                         sector  \n",
       "date                      asset                                                  \n",
       "2015-05-05 00:00:00+00:00 Equity(FIBBG000C2V3D6 [A])                 Technology  \n",
       "                          Equity(FIBBG005P7Q881 [AAL])              Industrials  \n",
       "                          Equity(FIBBG000B9XRY4 [AAPL])              Technology  \n",
       "                          Equity(FIBBG0025Y4RY4 [ABBV])             Health Care  \n",
       "                          Equity(FIBBG000MDCQC2 [ABC])              Health Care  \n",
       "...                                                                         ...  \n",
       "                          Equity(FIBBG001D8R5D0 [XYL])              Industrials  \n",
       "                          Equity(FIBBG000BH3GZ2 [YUM])   Consumer Discretionary  \n",
       "                          Equity(FIBBG000BKPL53 [ZBH])              Health Care  \n",
       "                          Equity(FIBBG000BX9WL1 [ZION])              Financials  \n",
       "                          Equity(FIBBG0039320N9 [ZTS])              Health Care  \n",
       "\n",
       "[464 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = run_pipeline(make_pipeline(), start_date='2015-05-05', end_date='2015-05-05')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class AnnualizedData(CustomFactor):\n",
    "#     # Get the sum of the last 4 reported values\n",
    "#     window_length = 260\n",
    "\n",
    "#     def compute(self, today, assets, out, asof_date, values):\n",
    "#         for asset in range(len(assets)):\n",
    "#             # unique asof dates indicate availability of new figures\n",
    "#             _, filing_dates = np.unique(asof_date[:, asset], return_index=True)\n",
    "#             quarterly_values = values[filing_dates[-4:], asset]\n",
    "#             # ignore annual windows with <4 quarterly data points\n",
    "#             if len(~np.isnan(quarterly_values)) != 4:    \n",
    "#                 out[asset] = np.nan\n",
    "#             else:\n",
    "#                 out[asset] = np.sum(quarterly_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class AnnualAvg(CustomFactor):\n",
    "#     window_length = 252\n",
    "    \n",
    "#     def compute(self, today, assets, out, values):\n",
    "#         out[:] = (values[0] + values[-1])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def factor_pipeline(factors):\n",
    "    start = time()\n",
    "    pipe = Pipeline({k: v(mask=UNIVERSE).rank() for k, v in factors.items()},\n",
    "                    screen=UNIVERSE)\n",
    "    result = run_pipeline(pipe, start_date=START, end_date=END)\n",
    "    return result, time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ValueFactors:\n",
    "    \"\"\"Definitions of factors for cross-sectional trading algorithms\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def PriceToSalesTTM(**kwargs):\n",
    "        \"\"\"Last closing price divided by sales per share\"\"\"    \n",
    "        return sharadar.Fundamentals.slice(dimension=\"ART\").PS.latest\n",
    "        return Fundamentals.ps_ratio.latest\n",
    "\n",
    "    @staticmethod\n",
    "    def PriceToEarningsTTM(**kwargs):\n",
    "        \"\"\"Closing price divided by earnings per share (EPS)\"\"\"\n",
    "        return sharadar.Fundamentals.slice(dimension=\"ART\").PE.latest\n",
    "        # return Fundamentals.pe_ratio.latest\n",
    " \n",
    "    @staticmethod\n",
    "    def PriceToDilutedEarningsTTM(mask):\n",
    "        \"\"\"Closing price divided by diluted EPS\"\"\"\n",
    "        last_close = EquityPricing.close.latest\n",
    "        diluted_eps = sharadar.Fundamentals.slice(dimension=\"ART\").EPSDIL.latest        \n",
    "        # diluted_eps = AnnualizedData(inputs = [Fundamentals.diluted_eps_earnings_reports_asof_date,\n",
    "        #                                        Fundamentals.diluted_eps_earnings_reports],\n",
    "        #                              mask=mask)        \n",
    "        return last_close / diluted_eps\n",
    "\n",
    "    @staticmethod\n",
    "    def PriceToForwardEarnings(**kwargs):\n",
    "        \"\"\"Price to Forward Earnings\"\"\"\n",
    "        return Fundamentals.forward_pe_ratio.latest\n",
    "    \n",
    "    @staticmethod\n",
    "    def DividendYield(**kwargs):\n",
    "        \"\"\"Dividends per share divided by closing price\"\"\"\n",
    "        # return Fundamentals.trailing_dividend_yield.latest\n",
    "        return sharadar.Fundamentals.slice(dimension=\"ART\").DIVYIELD.latest\n",
    "\n",
    "    @staticmethod\n",
    "    def PriceToFCF(mask):\n",
    "        \"\"\"Price to Free Cash Flow\"\"\"\n",
    "        # last_close = EquityPricing.close.latest\n",
    "        # fcf_share = AnnualizedData(inputs = [Fundamentals.fcf_per_share_asof_date,\n",
    "        #                                      Fundamentals.fcf_per_share],\n",
    "        #                            mask=mask)\n",
    "        # return last_close / fcf_share\n",
    "        return sharadar.Fundamentals.slice(dimension=\"ART\").FCFPS.latest\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def PriceToOperatingCashflow(mask):\n",
    "        \"\"\"Last Close divided by Operating Cash Flows\"\"\"\n",
    "        last_close = EquityPricing.close.latest\n",
    "        # cfo_per_share = AnnualizedData(inputs = [Fundamentals.cfo_per_share_asof_date,\n",
    "        #                                          Fundamentals.cfo_per_share],\n",
    "        #                                mask=mask)        \n",
    "        cfo_per_share = sharadar.Fundamentals.slice(dimension=\"ART\").NCFO.latest\n",
    "        return last_close / cfo_per_share\n",
    "\n",
    "    @staticmethod\n",
    "    def PriceToBook(mask):\n",
    "        \"\"\"Closing price divided by book value\"\"\"\n",
    "        # last_close = EquityPricing.close.latest\n",
    "        # book_value_per_share = AnnualizedData(inputs = [Fundamentals.book_value_per_share_asof_date,\n",
    "        #                                       Fundamentals.book_value_per_share],\n",
    "        #                                      mask=mask)        \n",
    "        # return last_close / book_value_per_share\n",
    "        return sharadar.Fundamentals.slice(dimension=\"ART\").PB.latest \n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def EVToFCF(mask):\n",
    "        # \"\"\"Enterprise Value divided by Free Cash Flows\"\"\"\n",
    "        # fcf = AnnualizedData(inputs = [Fundamentals.free_cash_flow_asof_date,\n",
    "        #                                Fundamentals.free_cash_flow],\n",
    "        #                      mask=mask)\n",
    "        # return Fundamentals.enterprise_value.latest / fcf\n",
    "        ev = sharadar.Fundamentals.slice(dimension=\"ART\").EV.latest \n",
    "        fcf = sharadar.Fundamentals.slice(dimension=\"ART\").FCF.latest \n",
    "        return ev / fcf\n",
    "\n",
    "    @staticmethod\n",
    "    def EVToEBITDA(mask):\n",
    "        \"\"\"Enterprise Value to Earnings Before Interest, Taxes, Deprecation and Amortization (EBITDA)\"\"\"\n",
    "#         ebitda = AnnualizedData(inputs = [Fundamentals.ebitda_asof_date,\n",
    "#                                           Fundamentals.ebitda],\n",
    "#                                 mask=mask)\n",
    "\n",
    "#         return Fundamentals.enterprise_value.latest / ebitda\n",
    "        return sharadar.Fundamentals.slice(dimension=\"ART\").EVEBITDA.latest \n",
    "\n",
    "    @staticmethod\n",
    "    def EBITDAYield(mask):\n",
    "        \"\"\"EBITDA divided by latest close\"\"\"\n",
    "        # ebitda = AnnualizedData(inputs = [Fundamentals.ebitda_asof_date,\n",
    "        #                                   Fundamentals.ebitda],\n",
    "        #                         mask=mask)\n",
    "        ebitda = sharadar.Fundamentals.slice(dimension=\"ART\").EBITDA.latest  \n",
    "        return EquityPricing.close.latest / ebitda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VALUE_FACTORS = {\n",
    "    'DividendYield'            : ValueFactors.DividendYield,\n",
    "    'EBITDAYield'              : ValueFactors.EBITDAYield,\n",
    "    'EVToEBITDA'               : ValueFactors.EVToEBITDA,\n",
    "    'EVToFCF'                  : ValueFactors.EVToFCF,\n",
    "    'PriceToBook'              : ValueFactors.PriceToBook,\n",
    "    'PriceToDilutedEarningsTTM': ValueFactors.PriceToDilutedEarningsTTM,\n",
    "    'PriceToFCF'               : ValueFactors.PriceToFCF,\n",
    "    # 'PriceToForwardEarnings'   : ValueFactors.PriceToForwardEarnings,\n",
    "    'PriceToOperatingCashflow' : ValueFactors.PriceToOperatingCashflow,\n",
    "    'PriceToEarningsTTM'       : ValueFactors.PriceToEarningsTTM,\n",
    "    'PriceToSalesTTM'          : ValueFactors.PriceToSalesTTM,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline run time 12.13 secs\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 233089 entries, (Timestamp('2014-01-02 00:00:00+0000', tz='UTC', freq='C'), Equity(FIBBG000C2V3D6 [A])) to (Timestamp('2015-12-31 00:00:00+0000', tz='UTC', freq='C'), Equity(FIBBG0039320N9 [ZTS]))\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   DividendYield              233089 non-null  float64\n",
      " 1   EBITDAYield                233089 non-null  float64\n",
      " 2   EVToEBITDA                 233089 non-null  float64\n",
      " 3   EVToFCF                    233089 non-null  float64\n",
      " 4   PriceToBook                233089 non-null  float64\n",
      " 5   PriceToDilutedEarningsTTM  232585 non-null  float64\n",
      " 6   PriceToFCF                 233089 non-null  float64\n",
      " 7   PriceToOperatingCashflow   233089 non-null  float64\n",
      " 8   PriceToEarningsTTM         233089 non-null  float64\n",
      " 9   PriceToSalesTTM            233089 non-null  float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 18.8+ MB\n"
     ]
    }
   ],
   "source": [
    "value_result, t = factor_pipeline(VALUE_FACTORS)\n",
    "print('Pipeline run time {:.2f} secs'.format(t))\n",
    "value_result.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.pipeline.factors import \n",
    "\n",
    "\n",
    "class MomentumFactors:\n",
    "    \"\"\"Custom Momentum Factors\"\"\"\n",
    "    class PercentAboveLow(CustomFactor):\n",
    "        \"\"\"Percentage of current close above low \n",
    "        in lookback window of window_length days\n",
    "        \"\"\"\n",
    "        inputs = [EquityPricing.close]\n",
    "        window_length = 252\n",
    "\n",
    "        def compute(self, today, assets, out, close):\n",
    "            out[:] = close[-1] / np.min(close, axis=0) - 1\n",
    "\n",
    "    class PercentBelowHigh(CustomFactor):\n",
    "        \"\"\"Percentage of current close below high \n",
    "        in lookback window of window_length days\n",
    "        \"\"\"\n",
    "        \n",
    "        inputs = [EquityPricing.close]\n",
    "        window_length = 252\n",
    "            \n",
    "        def compute(self, today, assets, out, close):\n",
    "            out[:] = close[-1] / np.max(close, axis=0) - 1\n",
    "\n",
    "    @staticmethod\n",
    "    def make_dx(timeperiod=14):\n",
    "        class DX(CustomFactor):\n",
    "            \"\"\"Directional Movement Index\"\"\"\n",
    "            inputs = [EquityPricing.high, \n",
    "                      EquityPricing.low, \n",
    "                      EquityPricing.close]\n",
    "            window_length = timeperiod + 1\n",
    "            \n",
    "            def compute(self, today, assets, out, high, low, close):\n",
    "                out[:] = [talib.DX(high[:, i], \n",
    "                                   low[:, i], \n",
    "                                   close[:, i], \n",
    "                                   timeperiod=timeperiod)[-1] \n",
    "                          for i in range(len(assets))]\n",
    "        return DX  \n",
    "\n",
    "    @staticmethod\n",
    "    def make_mfi(timeperiod=14):\n",
    "        class MFI(CustomFactor):\n",
    "            \"\"\"Money Flow Index\"\"\"\n",
    "            inputs = [EquityPricing.high, \n",
    "                      EquityPricing.low, \n",
    "                      EquityPricing.close,\n",
    "                      EquityPricing.volume]\n",
    "            window_length = timeperiod + 1\n",
    "            \n",
    "            def compute(self, today, assets, out, high, low, close, vol):\n",
    "                out[:] = [talib.MFI(high[:, i], \n",
    "                                    low[:, i], \n",
    "                                    close[:, i],\n",
    "                                    vol[:, i],\n",
    "                                    timeperiod=timeperiod)[-1] \n",
    "                          for i in range(len(assets))]\n",
    "        return MFI           \n",
    "\n",
    "    @staticmethod\n",
    "    def make_oscillator(fastperiod=12, slowperiod=26, matype=0):\n",
    "        class PPO(CustomFactor):\n",
    "            \"\"\"12/26-Day Percent Price Oscillator\"\"\"\n",
    "            inputs = [EquityPricing.close]\n",
    "            window_length = slowperiod\n",
    "\n",
    "            def compute(self, today, assets, out, close_prices):\n",
    "                out[:] = [talib.PPO(close,\n",
    "                                    fastperiod=fastperiod,\n",
    "                                    slowperiod=slowperiod, \n",
    "                                    matype=matype)[-1]\n",
    "                         for close in close_prices.T]\n",
    "        return PPO\n",
    "\n",
    "    @staticmethod\n",
    "    def make_stochastic_oscillator(fastk_period=5, slowk_period=3, slowd_period=3, \n",
    "                                   slowk_matype=0, slowd_matype=0):                \n",
    "        class StochasticOscillator(CustomFactor):\n",
    "            \"\"\"20-day Stochastic Oscillator \"\"\"\n",
    "            inputs = [EquityPricing.high, \n",
    "                      EquityPricing.low, \n",
    "                      EquityPricing.close]\n",
    "            outputs = ['slowk', 'slowd']\n",
    "            window_length = fastk_period * 2\n",
    "            \n",
    "            def compute(self, today, assets, out, high, low, close):\n",
    "                slowk, slowd = [talib.STOCH(high[:, i],\n",
    "                                            low[:, i],\n",
    "                                            close[:, i], \n",
    "                                            fastk_period=fastk_period,\n",
    "                                            slowk_period=slowk_period, \n",
    "                                            slowk_matype=slowk_matype, \n",
    "                                            slowd_period=slowd_period, \n",
    "                                            slowd_matype=slowd_matype)[-1] \n",
    "                                for i in range(len(assets))]\n",
    "\n",
    "                out.slowk[:], out.slowd[:] = slowk[-1], slowd[-1]\n",
    "        return StochasticOscillator\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_trendline(timeperiod=252):                \n",
    "        class Trendline(CustomFactor):\n",
    "            inputs = [EquityPricing.close]\n",
    "            \"\"\"52-Week Trendline\"\"\"\n",
    "            window_length = timeperiod\n",
    "\n",
    "            def compute(self, today, assets, out, close_prices):\n",
    "                out[:] = [talib.LINEARREG_SLOPE(close, \n",
    "                                   timeperiod=timeperiod)[-1] \n",
    "                          for close in close_prices.T]\n",
    "        return Trendline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOMENTUM_FACTORS = {\n",
    "    'Percent Above Low'            : MomentumFactors.PercentAboveLow,\n",
    "    'Percent Below High'           : MomentumFactors.PercentBelowHigh,\n",
    "    'Price Oscillator'             : MomentumFactors.make_oscillator(),\n",
    "    'Money Flow Index'             : MomentumFactors.make_mfi(),\n",
    "    'Directional Movement Index'   : MomentumFactors.make_dx(),\n",
    "    'Trendline'                    : MomentumFactors.make_trendline()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum_result, t = factor_pipeline(MOMENTUM_FACTORS)\n",
    "print('Pipeline run time {:.2f} secs'.format(t))\n",
    "momentum_result.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficiencyFactors:\n",
    "\n",
    "    @staticmethod\n",
    "    def CapexToAssets(mask):\n",
    "        \"\"\"Capital Expenditure divided by Total Assets\"\"\"\n",
    "        capex = AnnualizedData(inputs = [Fundamentals.capital_expenditure_asof_date,\n",
    "                                         Fundamentals.capital_expenditure],\n",
    "                                     mask=mask)   \n",
    "        assets = Fundamentals.total_assets.latest\n",
    "        return - capex / assets\n",
    "\n",
    "    @staticmethod\n",
    "    def CapexToSales(mask):\n",
    "        \"\"\"Capital Expenditure divided by Total Revenue\"\"\"\n",
    "        capex = AnnualizedData(inputs = [Fundamentals.capital_expenditure_asof_date,\n",
    "                                         Fundamentals.capital_expenditure],\n",
    "                                     mask=mask)   \n",
    "        revenue = AnnualizedData(inputs = [Fundamentals.total_revenue_asof_date,\n",
    "                                         Fundamentals.total_revenue],\n",
    "                                     mask=mask)         \n",
    "        return - capex / revenue\n",
    "  \n",
    "    @staticmethod\n",
    "    def CapexToFCF(mask):\n",
    "        \"\"\"Capital Expenditure divided by Free Cash Flows\"\"\"\n",
    "        capex = AnnualizedData(inputs = [Fundamentals.capital_expenditure_asof_date,\n",
    "                                         Fundamentals.capital_expenditure],\n",
    "                                     mask=mask)   \n",
    "        free_cash_flow = AnnualizedData(inputs = [Fundamentals.free_cash_flow_asof_date,\n",
    "                                         Fundamentals.free_cash_flow],\n",
    "                                     mask=mask)         \n",
    "        return - capex / free_cash_flow\n",
    "\n",
    "    @staticmethod\n",
    "    def EBITToAssets(mask):\n",
    "        \"\"\"Earnings Before Interest and Taxes (EBIT) divided by Total Assets\"\"\"\n",
    "        ebit = AnnualizedData(inputs = [Fundamentals.ebit_asof_date,\n",
    "                                         Fundamentals.ebit],\n",
    "                                     mask=mask)   \n",
    "        assets = Fundamentals.total_assets.latest\n",
    "        return ebit / assets\n",
    "    \n",
    "    @staticmethod\n",
    "    def CFOToAssets(mask):\n",
    "        \"\"\"Operating Cash Flows divided by Total Assets\"\"\"\n",
    "        cfo = AnnualizedData(inputs = [Fundamentals.operating_cash_flow_asof_date,\n",
    "                                         Fundamentals.operating_cash_flow],\n",
    "                                     mask=mask)   \n",
    "        assets = Fundamentals.total_assets.latest\n",
    "        return cfo / assets \n",
    "    \n",
    "    @staticmethod\n",
    "    def RetainedEarningsToAssets(mask):\n",
    "        \"\"\"Retained Earnings divided by Total Assets\"\"\"\n",
    "        retained_earnings = AnnualizedData(inputs = [Fundamentals.retained_earnings_asof_date,\n",
    "                                         Fundamentals.retained_earnings],\n",
    "                                     mask=mask)   \n",
    "        assets = Fundamentals.total_assets.latest\n",
    "        return retained_earnings / assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EFFICIENCY_FACTORS = {\n",
    "    'CFO To Assets' :EfficiencyFactors.CFOToAssets,\n",
    "    'Capex To Assets' :EfficiencyFactors.CapexToAssets,\n",
    "    'Capex To FCF' :EfficiencyFactors.CapexToFCF,\n",
    "    'Capex To Sales' :EfficiencyFactors.CapexToSales,\n",
    "    'EBIT To Assets' :EfficiencyFactors.EBITToAssets,\n",
    "    'Retained Earnings To Assets' :EfficiencyFactors.RetainedEarningsToAssets\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficiency_result, t = factor_pipeline(EFFICIENCY_FACTORS)\n",
    "print('Pipeline run time {:.2f} secs'.format(t))\n",
    "efficiency_result.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiskFactors:\n",
    "\n",
    "    @staticmethod\n",
    "    def LogMarketCap(mask):\n",
    "        \"\"\"Log of Market Capitalization log(Close Price * Shares Outstanding)\"\"\"\n",
    "        return np.log(MarketCap(mask=mask))\n",
    " \n",
    "    class DownsideRisk(CustomFactor):\n",
    "        \"\"\"Mean returns divided by std of 1yr daily losses (Sortino Ratio)\"\"\"\n",
    "        inputs = [USEquityPricing.close]\n",
    "        window_length = 252\n",
    "\n",
    "        def compute(self, today, assets, out, close):\n",
    "            ret = pd.DataFrame(close).pct_change()\n",
    "            out[:] = ret.mean().div(ret.where(ret<0).std())\n",
    "\n",
    "    @staticmethod\n",
    "    def MarketBeta(**kwargs):\n",
    "        \"\"\"Slope of 1-yr regression of price returns against index returns\"\"\"\n",
    "        return SimpleBeta(target=symbols('SPY'), regression_length=252) \n",
    "\n",
    "    class DownsideBeta(CustomFactor):\n",
    "        \"\"\"Slope of 1yr regression of returns on negative index returns\"\"\"\n",
    "        inputs = [USEquityPricing.close]\n",
    "        window_length = 252\n",
    "\n",
    "        def compute(self, today, assets, out, close):\n",
    "            t = len(close)\n",
    "            assets = pd.DataFrame(close).pct_change()\n",
    "            \n",
    "            start_date = (today - pd.DateOffset(years=1)).strftime('%Y-%m-%d')\n",
    "            spy = get_pricing('SPY', \n",
    "                              start_date=start_date, \n",
    "                              end_date=today.strftime('%Y-%m-%d')).reset_index(drop=True)\n",
    "            spy_neg_ret = (spy\n",
    "                           .close_price\n",
    "                           .iloc[-t:]\n",
    "                           .pct_change()\n",
    "                           .pipe(lambda x: x.where(x<0)))\n",
    "    \n",
    "            out[:] = assets.apply(lambda x: x.cov(spy_neg_ret)).div(spy_neg_ret.var())         \n",
    "\n",
    "    class Vol3M(CustomFactor):\n",
    "        \"\"\"3-month Volatility: Standard deviation of returns over 3 months\"\"\"\n",
    "\n",
    "        inputs = [USEquityPricing.close]\n",
    "        window_length = 63\n",
    "\n",
    "        def compute(self, today, assets, out, close):\n",
    "            out[:] = np.log1p(pd.DataFrame(close).pct_change()).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RISK_FACTORS = {\n",
    "    'Log Market Cap' : RiskFactors.LogMarketCap,\n",
    "    'Downside Risk'  : RiskFactors.DownsideRisk,\n",
    "    'Index Beta'     : RiskFactors.MarketBeta,\n",
    "#     'Downside Beta'  : RiskFactors.DownsideBeta,    \n",
    "    'Volatility 3M'  : RiskFactors.Vol3M,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_result, t = factor_pipeline(RISK_FACTORS)\n",
    "print('Pipeline run time {:.2f} secs'.format(t))\n",
    "risk_result.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def growth_pipeline():\n",
    "    revenue = AnnualizedData(inputs = [Fundamentals.total_revenue_asof_date,\n",
    "                                       Fundamentals.total_revenue],\n",
    "                             mask=UNIVERSE)\n",
    "    eps = AnnualizedData(inputs = [Fundamentals.diluted_eps_earnings_reports_asof_date,\n",
    "                                       Fundamentals.diluted_eps_earnings_reports],\n",
    "                             mask=UNIVERSE)    \n",
    "\n",
    "    return Pipeline({'Sales': revenue,\n",
    "                     'EPS': eps,\n",
    "                     'Total Assets': Fundamentals.total_assets.latest,\n",
    "                     'Net Debt': Fundamentals.net_debt.latest},\n",
    "                    screen=UNIVERSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_timer = time()\n",
    "growth_result = run_pipeline(growth_pipeline(), start_date=START, end_date=END)\n",
    "\n",
    "for col in growth_result.columns:\n",
    "    for month in [3, 12]:\n",
    "        new_col = col + ' Growth {}M'.format(month)\n",
    "        kwargs = {new_col: growth_result[col].pct_change(month*MONTH).groupby(level=1).rank()}        \n",
    "        growth_result = growth_result.assign(**kwargs)\n",
    "print('Pipeline run time {:.2f} secs'.format(time() - start_timer))\n",
    "growth_result.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QualityFactors:\n",
    "    \n",
    "    @staticmethod\n",
    "    def AssetTurnover(mask):\n",
    "        \"\"\"Sales divided by average of year beginning and year end assets\"\"\"\n",
    "\n",
    "        assets = AnnualAvg(inputs=[Fundamentals.total_assets],\n",
    "                           mask=mask)\n",
    "        sales = AnnualizedData([Fundamentals.total_revenue_asof_date,\n",
    "                                Fundamentals.total_revenue], mask=mask)\n",
    "        return sales / assets\n",
    "  \n",
    "    @staticmethod\n",
    "    def CurrentRatio(mask):\n",
    "        \"\"\"Total current assets divided by total current liabilities\"\"\"\n",
    "\n",
    "        assets = Fundamentals.current_assets.latest\n",
    "        liabilities = Fundamentals.current_liabilities.latest\n",
    "        return assets / liabilities\n",
    "    \n",
    "    @staticmethod\n",
    "    def AssetToEquityRatio(mask):\n",
    "        \"\"\"Total current assets divided by common equity\"\"\"\n",
    "\n",
    "        assets = Fundamentals.current_assets.latest\n",
    "        equity = Fundamentals.common_stock.latest\n",
    "        return assets / equity    \n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def InterestCoverage(mask):\n",
    "        \"\"\"EBIT divided by interest expense\"\"\"\n",
    "\n",
    "        ebit = AnnualizedData(inputs = [Fundamentals.ebit_asof_date,\n",
    "                                        Fundamentals.ebit], mask=mask)  \n",
    "        \n",
    "        interest_expense = AnnualizedData(inputs = [Fundamentals.interest_expense_asof_date,\n",
    "                                        Fundamentals.interest_expense], mask=mask)\n",
    "        return ebit / interest_expense\n",
    "\n",
    "    @staticmethod\n",
    "    def DebtToAssetRatio(mask):\n",
    "        \"\"\"Total Debts divided by Total Assets\"\"\"\n",
    "\n",
    "        debt = Fundamentals.total_debt.latest\n",
    "        assets = Fundamentals.total_assets.latest\n",
    "        return debt / assets\n",
    "    \n",
    "    @staticmethod\n",
    "    def DebtToEquityRatio(mask):\n",
    "        \"\"\"Total Debts divided by Common Stock Equity\"\"\"\n",
    "\n",
    "        debt = Fundamentals.total_debt.latest\n",
    "        equity = Fundamentals.common_stock.latest\n",
    "        return debt / equity    \n",
    "\n",
    "    @staticmethod\n",
    "    def WorkingCapitalToAssets(mask):\n",
    "        \"\"\"Current Assets less Current liabilities (Working Capital) divided by Assets\"\"\"\n",
    "\n",
    "        working_capital = Fundamentals.working_capital.latest\n",
    "        assets = Fundamentals.total_assets.latest\n",
    "        return working_capital / assets\n",
    " \n",
    "    @staticmethod\n",
    "    def WorkingCapitalToSales(mask):\n",
    "        \"\"\"Current Assets less Current liabilities (Working Capital), divided by Sales\"\"\"\n",
    "\n",
    "        working_capital = Fundamentals.working_capital.latest\n",
    "        sales = AnnualizedData([Fundamentals.total_revenue_asof_date,\n",
    "                                Fundamentals.total_revenue], mask=mask)        \n",
    "        return working_capital / sales          \n",
    "       \n",
    "        \n",
    "    class MertonsDD(CustomFactor):\n",
    "        \"\"\"Merton's Distance to Default \"\"\"\n",
    "        \n",
    "        inputs = [Fundamentals.total_assets,\n",
    "                  Fundamentals.total_liabilities, \n",
    "                  libor.value, \n",
    "                  USEquityPricing.close]\n",
    "        window_length = 252\n",
    "\n",
    "        def compute(self, today, assets, out, tot_assets, tot_liabilities, r, close):\n",
    "            mertons = []\n",
    "\n",
    "            for col_assets, col_liabilities, col_r, col_close in zip(tot_assets.T, tot_liabilities.T,\n",
    "                                                                     r.T, close.T):\n",
    "                vol_1y = np.nanstd(col_close)\n",
    "                numerator = np.log(\n",
    "                        col_assets[-1] / col_liabilities[-1]) + ((252 * col_r[-1]) - ((vol_1y ** 2) / 2))\n",
    "                mertons.append(numerator / vol_1y)\n",
    "\n",
    "            out[:] = mertons            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "QUALITY_FACTORS = {\n",
    "    'AssetToEquityRatio'    : QualityFactors.AssetToEquityRatio,\n",
    "    'AssetTurnover'         : QualityFactors.AssetTurnover,\n",
    "    'CurrentRatio'          : QualityFactors.CurrentRatio,\n",
    "    'DebtToAssetRatio'      : QualityFactors.DebtToAssetRatio,\n",
    "    'DebtToEquityRatio'     : QualityFactors.DebtToEquityRatio,\n",
    "    'InterestCoverage'      : QualityFactors.InterestCoverage,\n",
    "    'MertonsDD'             : QualityFactors.MertonsDD,\n",
    "    'WorkingCapitalToAssets': QualityFactors.WorkingCapitalToAssets,\n",
    "    'WorkingCapitalToSales' : QualityFactors.WorkingCapitalToSales,\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_result, t = factor_pipeline(QUALITY_FACTORS)\n",
    "print('Pipeline run time {:.2f} secs'.format(t))\n",
    "quality_result.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Payout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PayoutFactors:\n",
    "\n",
    "    @staticmethod\n",
    "    def DividendPayoutRatio(mask):\n",
    "        \"\"\"Dividends Per Share divided by Earnings Per Share\"\"\"\n",
    "\n",
    "        dps = AnnualizedData(inputs = [Fundamentals.dividend_per_share_earnings_reports_asof_date,\n",
    "                                        Fundamentals.dividend_per_share_earnings_reports], mask=mask)  \n",
    "        \n",
    "        eps = AnnualizedData(inputs = [Fundamentals.basic_eps_earnings_reports_asof_date,\n",
    "                                        Fundamentals.basic_eps_earnings_reports], mask=mask)\n",
    "        return dps / eps\n",
    "    \n",
    "    @staticmethod\n",
    "    def DividendGrowth(**kwargs):\n",
    "        \"\"\"Annualized percentage DPS change\"\"\"        \n",
    "        return Fundamentals.dps_growth.latest    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAYOUT_FACTORS = {\n",
    "    'Dividend Payout Ratio': PayoutFactors.DividendPayoutRatio,\n",
    "    'Dividend Growth': PayoutFactors.DividendGrowth\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payout_result, t = factor_pipeline(PAYOUT_FACTORS)\n",
    "print('Pipeline run time {:.2f} secs'.format(t))\n",
    "payout_result.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProfitabilityFactors:\n",
    "    \n",
    "    @staticmethod\n",
    "    def GrossProfitMargin(mask):\n",
    "        \"\"\"Gross Profit divided by Net Sales\"\"\"\n",
    "\n",
    "        gross_profit = AnnualizedData([Fundamentals.gross_profit_asof_date,\n",
    "                              Fundamentals.gross_profit], mask=mask)  \n",
    "        sales = AnnualizedData([Fundamentals.total_revenue_asof_date,\n",
    "                                Fundamentals.total_revenue], mask=mask)\n",
    "        return gross_profit / sales   \n",
    "    \n",
    "    @staticmethod\n",
    "    def NetIncomeMargin(mask):\n",
    "        \"\"\"Net income divided by Net Sales\"\"\"\n",
    "\n",
    "        net_income = AnnualizedData([Fundamentals.net_income_income_statement_asof_date,\n",
    "                              Fundamentals.net_income_income_statement], mask=mask)  \n",
    "        sales = AnnualizedData([Fundamentals.total_revenue_asof_date,\n",
    "                                Fundamentals.total_revenue], mask=mask)\n",
    "        return net_income / sales   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROFITABIILTY_FACTORS = {\n",
    "    'Gross Profit Margin': ProfitabilityFactors.GrossProfitMargin,\n",
    "    'Net Income Margin': ProfitabilityFactors.NetIncomeMargin,\n",
    "    'Return on Equity': Fundamentals.roe.latest,\n",
    "    'Return on Assets': Fundamentals.roa.latest,\n",
    "    'Return on Invested Capital': Fundamentals.roic.latest\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profitability_result, t = factor_pipeline(PAYOUT_FACTORS)\n",
    "print('Pipeline run time {:.2f} secs'.format(t))\n",
    "payout_result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profitability_pipeline().show_graph(format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookahead = [1, 5, 10, 20]\n",
    "returns = run_pipeline(Pipeline({'Returns{}D'.format(i): Returns(inputs=[USEquityPricing.close], \n",
    "                                          window_length=i+1, mask=UNIVERSE) for i in lookahead},\n",
    "                                screen=UNIVERSE),\n",
    "                       start_date=START, \n",
    "                       end_date=END)\n",
    "return_cols = ['Returns{}D'.format(i) for i in lookahead]\n",
    "returns.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([returns,\n",
    "                 value_result,\n",
    "                 momentum_result,\n",
    "                 quality_result,\n",
    "                 payout_result,\n",
    "                 growth_result,\n",
    "                 efficiency_result,\n",
    "                 risk_result], axis=1).sortlevel()\n",
    "data.index.names = ['date', 'asset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stock'] = data.index.get_level_values('asset').map(lambda x: x.asset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove columns and rows with less than 80% of data availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_before, cols_before = data.shape\n",
    "data = (data\n",
    "        .dropna(axis=1, thresh=int(len(data)*.8))\n",
    "        .dropna(thresh=int(len(data.columns) * .8)))\n",
    "data = data.fillna(data.median())\n",
    "rows_after, cols_after = data.shape\n",
    "print('{:,d} rows and {:,d} columns dropped'.format(rows_before-rows_after, cols_before-cols_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_index(1).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.clustermap(data.drop(['stock'] + return_cols, axis=1).corr())\n",
    "plt.gcf().set_size_inches((14,14));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(data.drop(return_cols, axis=1), drop_first=True)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shifted Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = data.loc[:, return_cols]\n",
    "shifted_y = []\n",
    "for col in y.columns:\n",
    "    t = int(re.search(r'\\d+', col).group(0))\n",
    "    shifted_y.append(y.groupby(level='asset')['Returns{}D'.format(t)].shift(-t).to_frame(col))\n",
    "y = pd.concat(shifted_y, axis=1)\n",
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(y[return_cols])\n",
    "ax.set_title('Return Distriubtions');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Returns1D'\n",
    "model_data = pd.concat([y[[target]], X], axis=1).dropna()\n",
    "model_data = model_data[model_data[target].between(model_data[target].quantile(.025), \n",
    "                                                   model_data[target].quantile(.975))]\n",
    "\n",
    "model = OLS(endog=model_data[target], exog=model_data.drop(target, axis=1))\n",
    "trained_model = model.fit()\n",
    "trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Returns5D'\n",
    "model_data = pd.concat([y[[target]], X], axis=1).dropna()\n",
    "model_data = model_data[model_data[target].between(model_data[target].quantile(.025), \n",
    "                                                   model_data[target].quantile(.975))]\n",
    "\n",
    "model = OLS(endog=model_data[target], exog=model_data.drop(target, axis=1))\n",
    "trained_model = model.fit()\n",
    "trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Returns10D'\n",
    "model_data = pd.concat([y[[target]], X], axis=1).dropna()\n",
    "model_data = model_data[model_data[target].between(model_data[target].quantile(.025), \n",
    "                                                   model_data[target].quantile(.975))]\n",
    "\n",
    "model = OLS(endog=model_data[target], exog=model_data.drop(target, axis=1))\n",
    "trained_model = model.fit()\n",
    "trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Returns20D'\n",
    "model_data = pd.concat([y[[target]], X], axis=1).dropna()\n",
    "model_data = model_data[model_data[target].between(model_data[target].quantile(.025), \n",
    "                                                   model_data[target].quantile(.975))]\n",
    "\n",
    "model = OLS(endog=model_data[target], exog=model_data.drop(target, axis=1))\n",
    "trained_model = model.fit()\n",
    "trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_split(d, nfolds=5, min_train=21):\n",
    "    \"\"\"Generate train/test dates for nfolds \n",
    "    with at least min_train train obs\n",
    "    \"\"\"\n",
    "    train_dates = d[:min_train].tolist()\n",
    "    n = int(len(dates)/(nfolds + 1)) + 1\n",
    "    test_folds = [d[i:i + n] for i in range(min_train, len(d), n)]\n",
    "    for test_dates in test_folds:\n",
    "        if len(train_dates) > min_train:\n",
    "            yield train_dates, test_dates\n",
    "        train_dates.extend(test_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Returns10D'\n",
    "outliers = .01\n",
    "model_data = pd.concat([y[[target]], X], axis=1).dropna().reset_index('asset', drop=True)\n",
    "model_data = model_data[model_data[target].between(*model_data[target].quantile([outliers, 1-outliers]).values)] \n",
    "\n",
    "model_data[target] = np.log1p(model_data[target])\n",
    "features = model_data.drop(target, axis=1).columns\n",
    "dates = model_data.index.unique()\n",
    "\n",
    "print(model_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data[target].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfolds = 250\n",
    "lr = LinearRegression()\n",
    "\n",
    "test_results, result_idx, preds = [], [], pd.DataFrame()\n",
    "for train_dates, test_dates in time_series_split(dates, nfolds=nfolds):\n",
    "    \n",
    "    X_train = model_data.loc[idx[train_dates], features]\n",
    "    y_train = model_data.loc[idx[train_dates], target]\n",
    "    lr.fit(X=X_train, y=y_train)\n",
    "    \n",
    "    X_test = model_data.loc[idx[test_dates], features]\n",
    "    y_test = model_data.loc[idx[test_dates], target]\n",
    "    y_pred = lr.predict(X_test)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_pred=y_pred, y_true=y_test))\n",
    "    ic, pval = spearmanr(y_pred, y_test)\n",
    "    \n",
    "    test_results.append([rmse, ic, pval])\n",
    "    preds = preds.append(y_test.to_frame('actuals').assign(predicted=y_pred))\n",
    "    result_idx.append(train_dates[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = pd.DataFrame(test_results, columns=['rmse', 'ic', 'pval'], index=result_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2)\n",
    "rolling_result = test_result.rolling(21).mean()\n",
    "rolling_result[['ic', 'pval']].plot(ax=axes[0], title='Information Coefficient')\n",
    "axes[0].axhline(test_result.ic.mean(), lw=1, ls='--', color='k')\n",
    "rolling_result[['rmse']].plot(ax=axes[1], title='Root Mean Squared Error')\n",
    "axes[1].axhline(test_result.rmse.mean(), lw=1, ls='--', color='k')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_cleaned = preds[(preds.predicted.between(*preds.predicted.quantile([.001, .999]).values))]\n",
    "sns.jointplot(x='actuals', y='predicted', data=preds_cleaned, stat_func=spearmanr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression: Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfolds = 250\n",
    "alphas = np.logspace(-10, 10, 21)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "result = pd.DataFrame()\n",
    "for alpha in alphas:\n",
    "    test_results = []\n",
    "    lr_ridge = Ridge(alpha=alpha)\n",
    "    for train_dates, test_dates in time_series_split(dates, nfolds=nfolds):\n",
    "\n",
    "        X_train = model_data.loc[idx[train_dates], features]\n",
    "        y_train = model_data.loc[idx[train_dates], target]\n",
    "        lr_ridge.fit(X=scaler.fit_transform(X_train), y=y_train)\n",
    "\n",
    "        X_test = model_data.loc[idx[test_dates], features]\n",
    "        y_test = model_data.loc[idx[test_dates], target]\n",
    "        y_pred = lr_ridge.predict(scaler.transform(X_test))\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(y_pred=y_pred, y_true=y_test))\n",
    "        ic, pval = spearmanr(y_pred, y_test)\n",
    "        \n",
    "        test_results.append([train_dates[-1], rmse, ic, pval, alpha])\n",
    "    result = result.append(pd.DataFrame(test_results, columns=['date', 'rmse', 'ic', 'pval', 'alpha']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.groupby('alpha').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y='ic', x='alpha', data=result);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = result.groupby('alpha')['ic', 'rmse'].mean().plot(logx=True)\n",
    "ax.axhline(test_result.ic.mean())\n",
    "ax.axhline(test_result.rmse.mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfolds = 250\n",
    "alphas = np.logspace(-5, 5, 11)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "result2 = pd.DataFrame()\n",
    "for alpha in alphas:\n",
    "    test_results = []\n",
    "    print(alpha)\n",
    "    lr_lasso = Lasso(alpha=alpha)\n",
    "    for i, (train_dates, test_dates) in enumerate(time_series_split(dates, nfolds=nfolds)):\n",
    "        if i % 50 == 0:\n",
    "            print('\\t{}'.format(i))\n",
    "\n",
    "        X_train = model_data.loc[idx[train_dates], features]\n",
    "        y_train = model_data.loc[idx[train_dates], target]\n",
    "        lr_lasso.fit(X=scaler.fit_transform(X_train), y=y_train)\n",
    "\n",
    "        X_test = model_data.loc[idx[test_dates], features]\n",
    "        y_test = model_data.loc[idx[test_dates], target]\n",
    "        y_pred = lr_lasso.predict(scaler.transform(X_test))\n",
    "\n",
    "#         mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "        rmse = np.sqrt(np.sum((y_test-y_pred)**2))\n",
    "        ic, pval = spearmanr(y_pred, y_test)\n",
    "        \n",
    "        test_results.append([train_dates[-1], rmse, ic, pval, alpha])\n",
    "    result2 = result2.append(pd.DataFrame(test_results, columns=['date', 'rmse', 'ic', 'pval', 'alpha']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2.groupby('alpha').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Returns10D'\n",
    "label = (y[target] > 0).astype(int).to_frame(target)\n",
    "model_data = pd.concat([label, X], axis=1).dropna().reset_index('asset', drop=True)\n",
    "\n",
    "features = model_data.drop(target, axis=1).columns\n",
    "dates = model_data.index.unique()\n",
    "\n",
    "print(model_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfolds = 250\n",
    "Cs = np.logspace(-5, 5, 11)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# logistic_result = pd.DataFrame(columns=['date', 'rmse', 'ic', 'pval', 'C'])\n",
    "logistic_preds = pd.DataFrame(columns=['actuals', 'predicted', 'C'])\n",
    "for C in Cs:\n",
    "    result = []\n",
    "    print(C)\n",
    "    log_reg = LogisticRegression(C=C)\n",
    "    for i, (train_dates, test_dates) in enumerate(time_series_split(dates, nfolds=nfolds)):\n",
    "\n",
    "        X_train = model_data.loc[idx[train_dates], features]\n",
    "        y_train = model_data.loc[idx[train_dates], target]\n",
    "        log_reg.fit(X=scaler.fit_transform(X_train), y=y_train)\n",
    "\n",
    "        X_test = model_data.loc[idx[test_dates], features]\n",
    "        y_test = model_data.loc[idx[test_dates], target]\n",
    "        y_pred = log_reg.predict_proba(scaler.transform(X_test))[:, 1]\n",
    "        \n",
    "#         rmse = np.sqrt(mean_squared_error(y_pred=y_pred, y_true=y_test))\n",
    "#         ic, pval = spearmanr(y_pred, y_test)\n",
    "        logistic_preds = (logistic_preds\n",
    "                          .append(y_test\n",
    "                                  .to_frame('actuals')\n",
    "                                  .assign(predicted=y_pred, C=C)))\n",
    "        \n",
    "#         result.append([train_dates[-1], rmse, ic, pval, alpha])\n",
    "#     logistic_result = logistic_result.append(pd.DataFrame(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logistic_preds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = logistic_preds.groupby('C').apply(lambda x: roc_auc_score(y_true=x.actuals.astype(int), \n",
    "                                                          y_score=x.predicted))\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc.sort_index(ascending=False).plot(logx=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_preds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Returns10D'\n",
    "label = (y[target] > 0).astype(int).to_frame(target)\n",
    "model_data = pd.concat([label, X], axis=1).dropna().reset_index('asset', drop=True)\n",
    "\n",
    "features = model_data.drop(target, axis=1).columns\n",
    "dates = model_data.index.unique()\n",
    "\n",
    "print(model_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TA-Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Technical:\n",
    "    @staticmethod\n",
    "    def make_bbands(timeperiod=5, nbdevup=2, nbdevdn=2, matype=0):\n",
    "        class BBANDS(CustomFactor):\n",
    "            \"\"\"Lower, middle, and upper Bollinger Bands\"\"\"\n",
    "\n",
    "            inputs = [USEquityPricing.close]\n",
    "            outputs = ['upper', 'middle', 'lower']\n",
    "            window_length = timeperiod\n",
    "\n",
    "            def compute(self, today, assets, out, close_prices):\n",
    "                bb = []\n",
    "                for close in close_prices.T:\n",
    "                    u, m, l = talib.BBANDS(close, timeperiod=timeperiod, \n",
    "                                nbdevup=nbdevup, nbdevdn=nbdevdn, \n",
    "                                matype=matype)\n",
    "                    bb.append((u[-1], m[-1], l[-1]))\n",
    "                out.upper[:], out.middle[:], out.lower[:] = list(zip(*bb))\n",
    "        return BBANDS\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_ema(timeperiod=30):\n",
    "        class EMA(CustomFactor):\n",
    "            \"\"\"Double Exponential Moving Average\"\"\"\n",
    "            inputs = [USEquityPricing.close]\n",
    "            window_length = timeperiod\n",
    "            \n",
    "            def compute(self, today, assets, out, close_prices):\n",
    "                out[:] = [talib.EMA(p, timeperiod=timeperiod)[-1] for p in close_prices.T]\n",
    "        return EMA \n",
    "    \n",
    "    @staticmethod\n",
    "    def make_dx(timeperiod=14):\n",
    "        class DX(CustomFactor):\n",
    "            \"\"\"Directional Movement Index\"\"\"\n",
    "            inputs = [USEquityPricing.high, \n",
    "                      USEquityPricing.low, \n",
    "                      USEquityPricing.close]\n",
    "            window_length = timeperiod + 1\n",
    "            \n",
    "            def compute(self, today, assets, out, high, low, close):\n",
    "                out[:] = [talib.DX(high[:, i], \n",
    "                                   low[:, i], \n",
    "                                   close[:, i], \n",
    "                                   timeperiod=timeperiod)[-1] \n",
    "                          for i in range(len(assets))]\n",
    "        return DX  \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def make_mfi(timeperiod=14):\n",
    "        class MFI(CustomFactor):\n",
    "            \"\"\"Money Flow Index\"\"\"\n",
    "            inputs = [USEquityPricing.high, \n",
    "                      USEquityPricing.low, \n",
    "                      USEquityPricing.close,\n",
    "                      USEquityPricing.volume]\n",
    "            window_length = timeperiod + 1\n",
    "            \n",
    "            def compute(self, today, assets, out, high, low, close, vol):\n",
    "                out[:] = [talib.MFI(high[:, i], \n",
    "                                    low[:, i], \n",
    "                                    close[:, i],\n",
    "                                    vol[:, i],\n",
    "                                    timeperiod=timeperiod)[-1] \n",
    "                          for i in range(len(assets))]\n",
    "        return MFI     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T03:19:05.197299Z",
     "start_time": "2018-09-10T03:19:05.193996Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_pipeline():\n",
    "    stocks = StaticAssets(symbols(['MSFT', 'AAPL']))\n",
    "#     DX = Technical.make_dx()\n",
    "    MFI = Technical.make_mfi()\n",
    "    \n",
    "    ewma = EWMA(inputs=[USEquityPricing.high],\n",
    "                        window_length=30, \n",
    "                        decay_rate=.2,\n",
    "                        mask=stocks)\n",
    "    bb = BollingerBands(window_length=30, k=2, mask=stocks)\n",
    "    return Pipeline({'adx': Technical.make_dx()(mask=stocks),\n",
    "                     'mfi': MFI(mask=stocks),\n",
    "                     'ewma': ewma,\n",
    "                     'lower': bb.lower,\n",
    "                     'mid': bb.middle,\n",
    "                     'up': bb.upper},\n",
    "                    screen=stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_timer = time()\n",
    "result = run_pipeline(test_pipeline(), \n",
    "                      start_date='2018-05-01',\n",
    "                      end_date='2018-07-31')\n",
    "print('Pipeline run time {:.2f} secs'.format(time() - start_timer))\n",
    "result.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum_pipeline_alt():\n",
    "    ewma = EWMA(inputs=[USEquityPricing.high],\n",
    "                        window_length=30, \n",
    "                        decay_rate=.2,\n",
    "                        mask=UNIVERSE)\n",
    "    bb = BollingerBands(window_length=30, k=2, mask=UNIVERSE)\n",
    "    \n",
    "    STOCH = MomentumFactors.make_stochastic_oscillator()\n",
    "    spo = STOCH(mask=UNIVERSE)\n",
    "\n",
    "    columns = {'ewma': ewma,\n",
    "               'so_slowk': spo.slowk,\n",
    "               'so_slowd': spo.slowd,\n",
    "               'bb_lower': bb.lower,\n",
    "               'bb_mid': bb.middle,\n",
    "               'bb_up': bb.upper}\n",
    "    columns.update({k: v(mask=UNIVERSE) for k, v in MOMENTUM_FACTORS.items()})\n",
    "    \n",
    "    return Pipeline(columns,\n",
    "                    screen=UNIVERSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
